{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "https://www.kaggle.com/zygmunt/goodbooks-10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2077</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2487</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2900</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3662</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3922</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  user_id  rating\n",
       "0        1      314       5\n",
       "1        1      439       3\n",
       "2        1      588       5\n",
       "3        1     1169       4\n",
       "4        1     1185       4\n",
       "5        1     2077       4\n",
       "6        1     2487       4\n",
       "7        1     2900       5\n",
       "8        1     3662       4\n",
       "9        1     3922       5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data = pd.read_csv('./data/ratings.csv')\n",
    "books_metadata = pd.read_csv('./data/books.csv')\n",
    "ratings_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the surprise dataset\n",
    "The framework expects a Dataset object with three feilds: userIDs, itemIDs, and rating\\\n",
    "Can load the dataset object from directly from the pandas dataframe, or from a csv\\\n",
    "A Reader class is used to parse the Dataset (each line (userID, itemID, rating)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from surprise import Dataset\n",
    "except ImportError:\n",
    "    !conda install -c conda-forge scikit-surprise -y\n",
    "    from surprise import Dataset\n",
    "\n",
    "from surprise import Reader\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5)) #Can change scale based on your requirements\n",
    "\n",
    "#The order of the data is important, must be user, item, user's rating for the item\n",
    "data = Dataset.load_from_df(ratings_data[['user_id', 'book_id', 'rating']], reader) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Suprise supports several recommender system algorithms\\\n",
    "See https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html \\\n",
    "The details have been abstracted away, so executing different algorithms is a simple as creating new classes\\\n",
    "<code> for algorithm in [SVD(),KNNBasic(),KNNWithMeans(),KNNWithZScore(), CoClustering(), SlopeOne(), SVDpp(), BaselineOnly()]:\\\n",
    "    #do stuff here using the Surprise algorithm API\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.8875  0.8885  0.8902  0.8887  0.0011  \n",
      "MAE (testset)     0.7077  0.7095  0.7102  0.7091  0.0011  \n",
      "Fit time          7.16    7.81    7.81    7.59    0.31    \n",
      "Test time         5.15    4.63    4.54    4.77    0.27    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.88746273, 0.88851717, 0.89015986]),\n",
       " 'test_mae': array([0.70768728, 0.70948701, 0.7101959 ]),\n",
       " 'fit_time': (7.157114028930664, 7.806339740753174, 7.814021825790405),\n",
       " 'test_time': (5.152777194976807, 4.625096559524536, 4.544297933578491)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "svd = SVD(verbose=True, n_epochs=3) \n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=3, verbose=True) #Auto-magic cross validation....NOICE!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready to predict\n",
    "Now that we are satisfied with the prediction accuracy we can use the full dataset to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f9b6ad632e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = data.build_full_trainset() #Prepare all the data we have for training\n",
    "\n",
    "svd.fit(trainset) #Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make some predictions\n",
    "\n",
    "Call the <code>.predict</code> method\\\n",
    "The <code>est</code> value is the ratings prediction for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=10, iid=100, r_ui=None, est=4.054441370797001, details={'was_impossible': False})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.predict(uid=10, iid=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User and item mappings\n",
    "Surprise refers to the user and item IDs provided in the data set as <code>raw user</code> and <code>raw item</code> IDs\\\n",
    "There are some useful functions for converting between <code>internal</code> and <code>raw</code> user IDs\\\n",
    "<code>.trainset.to_raw_uid\\\n",
    ".trainset.to_raw_iid\\\n",
    ".trainset.to_inner_uid\\\n",
    ".trainset.to_inner_iid\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5379"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.to_raw_uid(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.to_raw_iid(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom predicitons\n",
    "Can go under the hood of the SVD and use the user and item embeddings, and biases to make custom predictions\\\n",
    "Suprise has some useful functions from the uid an item to user and item mappings respectively\\\n",
    "\n",
    "To demonstrate making a custom predciton, we can define a dot product prediciton\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 100\n"
     ]
    }
   ],
   "source": [
    "user = 5379 #Surprise preserves the type of the raw user and item embeddings\n",
    "item = 101\n",
    "\n",
    "uid = trainset.to_inner_uid(user) #map the raw user ID to the internal uid\n",
    "iid = trainset.to_inner_iid(item)  #map the raw item ID to the internal iid \n",
    "print(uid, iid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.46516253e-02 -1.80309517e-02 -3.86988943e-02  3.28080519e-02\n",
      "  2.16188698e-02 -3.45825544e-02 -1.94436508e-01  1.03234706e-01\n",
      " -1.02937169e-01  3.96642074e-02  1.21778241e-03 -1.40578330e-01\n",
      "  3.53408770e-03 -5.13682382e-03 -3.85221543e-02 -9.79488566e-02\n",
      "  1.78449769e-02  1.39383840e-01  9.52608565e-02 -9.96451116e-02\n",
      " -5.66504679e-02 -6.47967722e-02  8.35129584e-02 -6.39213449e-02\n",
      "  1.21616903e-01  1.33954250e-01 -5.02637368e-03  8.62671531e-02\n",
      "  3.86005371e-02 -1.43919190e-01  3.61908289e-02  6.62229710e-03\n",
      " -1.13684351e-01  1.08505001e-02 -1.17555302e-01 -1.56395946e-01\n",
      "  5.07502638e-02 -7.38891108e-02  1.09686369e-02 -1.88371140e-02\n",
      " -1.02219768e-02  2.34453578e-02 -4.23290111e-02 -1.41049948e-02\n",
      "  1.04194775e-01 -1.58551764e-01 -2.09813765e-02 -1.22386611e-01\n",
      "  1.72667695e-01 -4.73269647e-02 -1.46604671e-01  1.36401160e-01\n",
      " -2.52086121e-02 -9.06468823e-02  9.95892558e-02 -3.70157712e-02\n",
      "  7.02213429e-02 -3.09394791e-02  6.58677420e-02  4.44365084e-02\n",
      " -4.70962136e-02  1.27114818e-01  5.39722805e-02  1.04513280e-02\n",
      " -1.77643600e-01 -7.59344093e-02  9.38934959e-02  3.58900264e-02\n",
      "  1.66661638e-02 -9.04543739e-03 -4.26431168e-02 -3.63207291e-02\n",
      "  2.36149143e-02 -1.20623003e-01  1.15155216e-01  1.25933365e-02\n",
      " -5.64064972e-02  9.06533560e-02 -1.56754267e-01  5.84854418e-02\n",
      "  1.06900593e-01 -1.55015933e-02 -3.73955033e-04  1.11067596e-01\n",
      " -9.66790577e-03  8.06520190e-02 -8.55909821e-02  2.30633477e-03\n",
      " -1.61227340e-01  3.97407444e-02 -1.69721245e-01  1.67750614e-04\n",
      "  9.51238919e-03  5.80507388e-02 -8.29736736e-02 -7.80757974e-02\n",
      "  1.24093449e-01  1.03355923e-01 -8.49871175e-03  7.43823899e-02]\n"
     ]
    }
   ],
   "source": [
    "uvector = svd.pu[uid] #extract the user embedding\n",
    "print(uvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00820788  0.01007331 -0.11177818  0.06305484  0.07670616  0.0611004\n",
      "  0.12343619 -0.06171201 -0.00659903 -0.01782585  0.0612415  -0.06326322\n",
      "  0.10982753 -0.01090559 -0.05679156 -0.0786478   0.07102125 -0.00165396\n",
      "  0.04730088  0.0639501  -0.02847888  0.08069979  0.07783425 -0.01639082\n",
      " -0.04881306  0.04410616  0.15406206 -0.06788968  0.01585481 -0.07401798\n",
      "  0.07959198 -0.10021469 -0.04011538  0.01401352  0.00303613 -0.1114238\n",
      " -0.20390406  0.08165459 -0.01418364 -0.09003103 -0.11693414 -0.13593316\n",
      " -0.02444804  0.16151701  0.03237139  0.02225994 -0.03145099 -0.09472469\n",
      " -0.00586675  0.05263351 -0.03287573 -0.00400836 -0.10360958 -0.06031982\n",
      "  0.16979077 -0.05874401 -0.05477965 -0.01749883 -0.0259682   0.08039657\n",
      "  0.03382609  0.04213696 -0.02704677 -0.18044848 -0.19700545  0.11909409\n",
      "  0.14304131  0.05689868  0.0591437   0.28775542 -0.12050541 -0.1060383\n",
      "  0.00425844  0.03817375  0.09803934 -0.12300912 -0.24121863 -0.10585198\n",
      "  0.20442726 -0.28935598 -0.02507758  0.25149491 -0.06582015  0.05785669\n",
      " -0.03167351  0.02354055  0.00879496 -0.19999874  0.10212879 -0.10837153\n",
      "  0.12504121  0.01634246  0.02139146 -0.11279992 -0.04804635 -0.14550454\n",
      "  0.00948501 -0.23682562  0.05563909  0.0406268 ]\n"
     ]
    }
   ],
   "source": [
    "ivector = svd.qi[iid] #extract the user embedding \n",
    "print(ivector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06412638515474735\n"
     ]
    }
   ],
   "source": [
    "ubias = svd.bu[uid] #user bias \n",
    "print(ubias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02485504402293399\n"
     ]
    }
   ],
   "source": [
    "ibias = svd.bi[iid] #item bias\n",
    "print(ibias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8565335989797873\n"
     ]
    }
   ],
   "source": [
    "global_mean = svd.trainset.global_mean #Think of this as 'zero' i.e., normalized data\n",
    "print(global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.94831524298186\n"
     ]
    }
   ],
   "source": [
    "dp = np.dot(uvector,ivector)\n",
    "est = global_mean + ubias + ibias + dp\n",
    "print(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "import random\n",
    "\n",
    "def get_book_id(book_title, metadata):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets the book ID for a book title based on the closest match in the metadata dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    existing_titles = list(metadata['title'].values)\n",
    "    closest_titles = difflib.get_close_matches(book_title, existing_titles) #Returns the titles that are similar \n",
    "    \n",
    "    #Assuming the book title is in the dataset, it must be the cloeset match\n",
    "    book_id = metadata[metadata['title'] == closest_titles[0]]['id'].values[0] \n",
    "    return book_id\n",
    "\n",
    "def get_book_info(book_id, metadata):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns some basic information about a book given the book id and the metadata dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    book_info = metadata[metadata['id'] == book_id][['id', 'isbn', \n",
    "                                                    'authors', 'title', 'original_title']]\n",
    "    return book_info.to_dict(orient='records')\n",
    "\n",
    "def predict_review(user_id, book_title, model, metadata):\n",
    "    \n",
    "    \"\"\"\n",
    "    Predicts the review (on a scale of 1-5) that a user would assign to a specific book. \n",
    "    \"\"\"\n",
    "    \n",
    "    book_id = get_book_id(book_title, metadata)\n",
    "    review_prediction = model.predict(uid=user_id, iid=book_id)\n",
    "    return review_prediction.est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom recommendation: Return the first book that the use would rate >= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def generate_recommendation(user_id, model, metadata, thresh=4):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a book recommendation for a user based on a rating threshold. Only\n",
    "    books with a predicted rating at or above the threshold will be recommended\n",
    "    \"\"\"\n",
    "    \n",
    "    book_titles = list(metadata['title'].values)\n",
    "    random.shuffle(book_titles)\n",
    "    \n",
    "    for book_title in book_titles:\n",
    "        rating = predict_review(user_id, book_title, model, metadata)\n",
    "        if rating >= thresh:\n",
    "            book_id = get_book_id(book_title, metadata)\n",
    "            return get_book_info(book_id, metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 8200,\n",
       "  'isbn': '1926760689',\n",
       "  'authors': 'pleasefindthis, Iain S. Thomas, Jon Ellis',\n",
       "  'title': 'I Wrote This For You',\n",
       "  'original_title': 'I Wrote This For You'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_recommendation(1000, svd, books_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top k recommendations\\\n",
    "The following runs a bit slow since it is an exhaustive search\n",
    "It can be optimipzied, for each user based on pre-computed user and item embeddings\\\n",
    "Once the raiting information is not updated, the user-item embeddings will be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def generate_recommendation_top_k(user_id, model, metadata, thresh=4, k=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a book recommendation for a user based on a rating threshold. Only\n",
    "    the top k books with a predicted rating at or above the threshold will be recommended\n",
    "    \"\"\"\n",
    "    \n",
    "    book_titles = list(metadata['title'].values)\n",
    "    random.shuffle(book_titles)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    for book_title in book_titles:\n",
    "        rating = predict_review(user_id, book_title, model, metadata)\n",
    "        if rating >= thresh:\n",
    "            book_id = get_book_id(book_title, metadata)\n",
    "            recommendations.append(get_book_info(book_id, metadata)[0])\n",
    "            if len(recommendations) == k:\n",
    "                return recommendations\n",
    "            \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 3963,\n",
       "  'isbn': '553268929',\n",
       "  'authors': 'Pat Conroy',\n",
       "  'title': 'The Great Santini',\n",
       "  'original_title': 'The Great Santini'},\n",
       " {'id': 389,\n",
       "  'isbn': '076531178X',\n",
       "  'authors': 'Brandon Sanderson',\n",
       "  'title': 'The Final Empire (Mistborn, #1)',\n",
       "  'original_title': 'Mistborn : The Final Empire'},\n",
       " {'id': 5768,\n",
       "  'isbn': '62267175',\n",
       "  'authors': 'Nicole  Williams',\n",
       "  'title': 'Crush (Crash, #3)',\n",
       "  'original_title': 'Crush'},\n",
       " {'id': 7799,\n",
       "  'isbn': '316084255',\n",
       "  'authors': 'Yana Toboso, Tomo Kimura',\n",
       "  'title': 'Black Butler, Vol. 2 (Black Butler, #2)',\n",
       "  'original_title': '黒執事 II [Kuroshitsuji II]'},\n",
       " {'id': 2988,\n",
       "  'isbn': '1557091552',\n",
       "  'authors': 'Carolyn Keene, Russell H. Tandy, Sara Paretsky',\n",
       "  'title': 'The Secret of the Old Clock (Nancy Drew, #1)',\n",
       "  'original_title': 'The Secret of the Old Clock (Nancy Drew Mystery Stories, #1)'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_recommendation_top_k(1000, svd, books_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom algorithm\n",
    "https://surprise.readthedocs.io/en/stable/building_custom_algo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the AlgoBase class\\\n",
    "Provide implementatios for the <code>fit</code> and <code>estimate</code> methods\\\n",
    "General rule, where applicable, call the parent method before providing custom implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from surprise import AlgoBase\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "class MyOwnAlgorithm(AlgoBase):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Always call base method before doing anything.\n",
    "        AlgoBase.__init__(self)\n",
    "\n",
    "    def fit(self, trainset):\n",
    "\n",
    "        # Here again: call base method before doing anything.\n",
    "        AlgoBase.fit(self, trainset)\n",
    "\n",
    "        # Compute the average rating. We might as well use the\n",
    "        # trainset.global_mean attribute ;)\n",
    "        self.the_mean = np.mean([r for (_, _, r) in\n",
    "                                 self.trainset.all_ratings()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "\n",
    "        return self.the_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm MyOwnAlgorithm on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9850  0.9815  0.9832  0.9833  0.9867  0.9839  0.0018  \n",
      "MAE (testset)     0.7868  0.7848  0.7868  0.7861  0.7899  0.7869  0.0017  \n",
      "Fit time          0.52    1.24    1.24    1.24    1.22    1.09    0.28    \n",
      "Test time         2.21    2.25    2.19    2.16    2.22    2.20    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.98499663, 0.98151183, 0.9832459 , 0.98327713, 0.98666977]),\n",
       " 'test_mae': array([0.78680473, 0.78477723, 0.78680755, 0.78613047, 0.78987618]),\n",
       " 'fit_time': (0.522496223449707,\n",
       "  1.2396535873413086,\n",
       "  1.2383008003234863,\n",
       "  1.2426872253417969,\n",
       "  1.2155101299285889),\n",
       " 'test_time': (2.2112576961517334,\n",
       "  2.247276782989502,\n",
       "  2.1896824836730957,\n",
       "  2.1584644317626953,\n",
       "  2.215437650680542)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = MyOwnAlgorithm()\n",
    "cross_validate(algo, data, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.856887</td>\n",
       "      <td>37.201967</td>\n",
       "      <td>7.367610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyOwnAlgorithm</th>\n",
       "      <td>0.983940</td>\n",
       "      <td>0.534446</td>\n",
       "      <td>4.831557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                test_rmse   fit_time  test_time\n",
       "Algorithm                                      \n",
       "SVD              0.856887  37.201967   7.367610\n",
       "MyOwnAlgorithm   0.983940   0.534446   4.831557"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from surprise import *\n",
    "\n",
    "benchmark = []\n",
    "\n",
    "for algorithm in [SVD(), MyOwnAlgorithm()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=2, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link to a dash baord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sixer\n",
      "  Downloading sixer-1.6.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: sixer\n",
      "Successfully installed sixer-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__main__'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:80/proxy/80/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import dash\n",
    "except ImportError:\n",
    "    !conda install -c conda-forge -c plotly jupyter-dash -y\n",
    "    import dash\n",
    "    \n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "\n",
    "import pandas as pd\n",
    "import dash_table\n",
    "\n",
    "from six import iteritems\n",
    "\n",
    "def _uid_to_username(uid):\n",
    "    return trainset.to_raw_uid(uid)\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "proxy_port = 80\n",
    "\n",
    "_default_userID = 1000\n",
    "_default_un = _uid_to_username(_default_userID)\n",
    "df  = pd.DataFrame(generate_recommendation_top_k(_default_userID, svd, books_metadata))\n",
    "\n",
    "#Make data for drop down\n",
    "options_data = []\n",
    "for (raw, inner ) in iteritems(trainset._raw2inner_id_users):\n",
    "    options_data.append({ 'label': raw , 'value' : inner })\n",
    "    \n",
    "\n",
    "#app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "app = JupyterDash(__name__, \n",
    "                  external_stylesheets=external_stylesheets,\n",
    "                  requests_pathname_prefix='/proxy/' + str(proxy_port) + '/')\n",
    "\n",
    "dropdown = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='demo-dropdown',\n",
    "        options=options_data,\n",
    "        value=_default_userID\n",
    "    ),\n",
    "    html.Div(id='dd-output-container', children='Book recommendations for user {}'.format(_default_un))\n",
    "])\n",
    "\n",
    "\n",
    "table = dash_table.DataTable(\n",
    "    id='table',\n",
    "    columns=[{\"name\": i, \"id\": i} for i in df.columns],\n",
    "    data=df.to_dict('records'),\n",
    ")\n",
    "\n",
    "app.layout = html.Div([dropdown, table])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [dash.dependencies.Output('dd-output-container', 'children'), dash.dependencies.Output(\"table\", \"data\")],\n",
    "    [dash.dependencies.Input('demo-dropdown', 'value')])\n",
    "def update_output(value):\n",
    "    df  = pd.DataFrame(generate_recommendation_top_k(int(value), svd, books_metadata))\n",
    "    _un = _uid_to_username(value)\n",
    "    return 'Book recommendations for user {}'.format(_un), df.to_dict('records')\n",
    "\n",
    "\n",
    "srv = app.run_server(debug=True, use_reloader=False, port=proxy_port)\n",
    "srv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://nbnt35tkym.clg07azjl.paperspacegradient.com/proxy/80/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#not work\n",
    "## This is a sharable version of the link (for Paperspace)\n",
    "import os\n",
    "nid = os.environ['PAPERSPACE_NOTEBOOK_ID']\n",
    "cid = os.environ['PAPERSPACE_CLUSTER_ID']\n",
    "print('https://'+nid+'.'+cid+'.paperspacegradient.com/proxy/80/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "https://towardsdatascience.com/how-you-can-build-simple-recommender-systems-with-surprise-b0d32a8e4802 \\\n",
    "https://www.kaggle.com/zygmunt/goodbooks-10k \\\n",
    "https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html \\\n",
    "https://surprise.readthedocs.io/en/stable/building_custom_algo.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
